{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   +-+-+-+-+-+-+ +-+-+-+-+-+-+-+-+-+-+\n",
    "#   |L|i|n|e|a|r| |R|e|g|r|e|s|s|i|o|n|\n",
    "#   +-+-+-+-+-+-+ +-+-+-+-+-+-+-+-+-+-+\n",
    "#                                                       \n",
    "#   ________  ________  ________  ________  ___  __    \n",
    "#  |\\   ____\\|\\   __  \\|\\   __  \\|\\   __  \\|\\  \\|\\  \\   \n",
    "#  \\ \\  \\___|\\ \\  \\|\\  \\ \\  \\|\\  \\ \\  \\|\\  \\ \\  \\/  /|_ \n",
    "#   \\ \\_____  \\ \\   ____\\ \\   __  \\ \\   _  _\\ \\   ___  \\\n",
    "#    \\|____|\\  \\ \\  \\___|\\ \\  \\ \\  \\ \\  \\\\  \\\\ \\  \\\\ \\  \\\n",
    "#      ____\\_\\  \\ \\__\\    \\ \\__\\ \\__\\ \\__\\\\ _\\\\ \\__\\\\ \\__\\\n",
    "#     |\\_________\\|__|     \\|__|\\|__|\\|__|\\|__|\\|__| \\|__|\n",
    "#     \\|_________| \n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f57a35597f0>\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import requests\n",
    "from faker import Faker\n",
    "import ujson as json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from numpy import random \n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "from elasticsearch_dsl import Search, DocType, Date, Integer, Keyword, Text\n",
    "from datetime import datetime\n",
    "from elasticsearch_dsl.connections import connections\n",
    "import requests\n",
    "from random import randint\n",
    "from pandas.io.json import json_normalize\n",
    "from pandasticsearch import DataFrame\n",
    "from pandasticsearch import Select\n",
    "\n",
    "\n",
    "\n",
    "ES_HOST = 'http://ec2-34-205-15-150.compute-1.amazonaws.com:9200'\n",
    "ES_HOST_wo_PORT = 'http://ec2-34-205-15-150.compute-1.amazonaws.com'\n",
    "INDEX = \"eda_xxsmall\"\n",
    "ES_PORT = \"9200\"\n",
    "DOC_TYPE=\"user\"\n",
    "es = Elasticsearch(ES_HOST)\n",
    "es.indices.put_settings(index=INDEX,\n",
    "                        body= {\"index\" : {\n",
    "                                \"max_result_window\" : 750000\n",
    "                              }})\n",
    "\n",
    "print(spark)\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "###\n",
    "###  Import SparkSession and LinearRegression from \n",
    "###  pyspark.sql and pysparl.ml.regression respectively \n",
    "###  \n",
    "##################################################################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "###\n",
    "###  SparkSession - a new entry point\n",
    "###  A SparkSession can be created using a builder pattern. \n",
    "###  The builder will automatically reuse an existing SparkContext \n",
    "###  if one exists; and create a SparkContext if it does not exist. \n",
    "###  \n",
    "##################################################################\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LModel\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Elasticsearch Query\n",
    "query = {\n",
    "            \"from\" : 0, \n",
    "            \"size\" : 10000,\n",
    "            \"query\": {\n",
    "                        \"match_all\": {}\n",
    "                     }\n",
    "            }\n",
    "## Import Data\n",
    "result_dict = es.search(index=INDEX, body=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "###\n",
    "###  Importing data into Panda Dataframe first via Pandastactic and than \n",
    "###  creating a spark Dataframe.  \n",
    "###  @Todo create Spark datframe directly from Elastcisearch \n",
    "###  \n",
    "##################################################################\n",
    "\n",
    "result_dict = es.search(index=INDEX, body=query)\n",
    "pandas_df = Select.from_dict(result_dict).to_pandas()\n",
    "pandas_df = pandas_df.set_index(['_id'])\n",
    "pandas_df.drop(['_index', '_score', '_type'],inplace=True,axis=1,errors='ignore')\n",
    "\n",
    "spark_df = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Avg Order Value: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- days_since_last_purchase: long (nullable = true)\n",
      " |-- discount_percentage: long (nullable = true)\n",
      " |-- email_unsubscribe: boolean (nullable = true)\n",
      " |-- f_score: long (nullable = true)\n",
      " |-- lifecycle: string (nullable = true)\n",
      " |-- m_score: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- num_of_orders: long (nullable = true)\n",
      " |-- r_score: long (nullable = true)\n",
      " |-- revenue: long (nullable = true)\n",
      " |-- rfm_score: long (nullable = true)\n",
      " |-- segments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- signup_date: string (nullable = true)\n",
      " |-- total_discount_revenue: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6245"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A few things we need to do before Spark can accept the data!\n",
    "# It needs to be in the form of two columns\n",
    "# (\"label\",\"features\")\n",
    "\n",
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Avg Order Value',\n",
       " 'City',\n",
       " 'days_since_last_purchase',\n",
       " 'discount_percentage',\n",
       " 'email_unsubscribe',\n",
       " 'f_score',\n",
       " 'lifecycle',\n",
       " 'm_score',\n",
       " 'name',\n",
       " 'num_of_orders',\n",
       " 'r_score',\n",
       " 'revenue',\n",
       " 'rfm_score',\n",
       " 'segments',\n",
       " 'signup_date',\n",
       " 'total_discount_revenue']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['Avg Order Value','days_since_last_purchase'],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(spark_df)\n",
    "\n",
    "output.select(\"features\").show()\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+------------------------+-------------------+-----------------+-------+---------------+-------+-----------------+-------------+-------+-------+---------+--------------------+-------------------+----------------------+--------------------+\n",
      "|   Avg Order Value|     City|days_since_last_purchase|discount_percentage|email_unsubscribe|f_score|      lifecycle|m_score|             name|num_of_orders|r_score|revenue|rfm_score|            segments|        signup_date|total_discount_revenue|            features|\n",
      "+------------------+---------+------------------------+-------------------+-----------------+-------+---------------+-------+-----------------+-------------+-------+-------+---------+--------------------+-------------------+----------------------+--------------------+\n",
      "|            2432.0|Hyderabad|                      48|                  9|            false|      1|Repeat_Sleeping|      4|  Henry Patterson|            2|      5|   4864|       10|                  []|2016-04-29T01:57:59|                437.76|[2432.0,48.0,9.0,...|\n",
      "|            3993.5|Bangalore|                      95|                 27|            false|      1| Repeat_Churned|      5|Christina Bennett|            2|      3|   7987|        9|[High_Discount_Se...|2015-06-27T03:16:48|               2156.49|[3993.5,95.0,27.0...|\n",
      "|           1114.75|    Delhi|                       5|                 25|            false|      3|  Repeat_Active|      4|   Joseph Lang MD|            4|      9|   4459|       16|               [NCR]|2015-11-01T06:32:09|               1114.75|[1114.75,5.0,25.0...|\n",
      "|2559.3333333333335|Ahmedabad|                      71|                 22|            false|      2| Repeat_Churned|      5|  Janice Martinez|            3|      4|   7678|       11|                  []|2015-07-28T10:35:23|               1689.16|[2559.33333333333...|\n",
      "|            1643.0|    Thane|                      84|                 13|            false|      4|  Loyal_Churned|      5|       Duane West|            6|      4|   9858|       13|                  []|2015-07-22T13:20:55|               1281.54|[1643.0,84.0,13.0...|\n",
      "|            2009.0|Bangalore|                      89|                 24|             true|      2| Repeat_Churned|      5|      David Bowen|            3|      4|   6027|       11|                  []|2016-01-25T17:08:55|               1446.48|[2009.0,89.0,24.0...|\n",
      "|            2716.5|    Delhi|                      32|                 16|            false|      1|Repeat_Sleeping|      5|      Craig Stout|            2|      6|   5433|       12|               [NCR]|2015-10-09T06:26:23|                869.28|[2716.5,32.0,16.0...|\n",
      "| 614.3333333333334|Bangalore|                      41|                  5|            false|      5| Loyal_Sleeping|      5|   Sandra Sanchez|           12|      6|   7372|       16|                  []|2015-08-20T20:19:57|                 368.6|[614.333333333333...|\n",
      "| 543.1818181818181|    Delhi|                      40|                  7|            false|      5| Loyal_Sleeping|      5|      Lisa Ashley|           11|      6|   5975|       16|               [NCR]|2016-05-07T11:03:14|                418.25|[543.181818181818...|\n",
      "|            3846.0|    Delhi|                      58|                 17|            false|      1|Repeat_Sleeping|      5|  Amanda Figueroa|            2|      5|   7692|       11|[NCR, High_Cart_V...|2015-10-16T05:29:25|               1307.64|[3846.0,58.0,17.0...|\n",
      "|            1057.0|   Mumbai|                      82|                 10|            false|      3|  Loyal_Churned|      5|   Jennifer Allen|            5|      4|   5285|       12|                  []|2016-02-05T15:48:35|                 528.5|[1057.0,82.0,10.0...|\n",
      "| 522.3333333333334|Ahmedabad|                      55|                 22|            false|      4| Loyal_Sleeping|      4|    Aaron Jimenez|            9|      5|   4701|       13|                  []|2016-05-01T10:38:30|               1034.22|[522.333333333333...|\n",
      "|            3790.5|    Delhi|                       3|                  6|            false|      1|  Repeat_Active|      5|   Robert Holland|            2|      9|   7581|       15|[NCR, High_Cart_V...|2016-03-14T09:49:44|                454.86|[3790.5,3.0,6.0,1...|\n",
      "|            2291.0|Bangalore|                      44|                 21|            false|      3|Repeat_Sleeping|      5|    Douglas Young|            4|      6|   9164|       14|                  []|2016-05-08T18:54:43|               1924.44|[2291.0,44.0,21.0...|\n",
      "|            3320.5|   Mumbai|                      89|                 16|            false|      1| Repeat_Churned|      5|        Amy Vance|            2|      4|   6641|       10|   [High_Cart_Value]|2016-03-07T18:16:10|               1062.56|[3320.5,89.0,16.0...|\n",
      "|            3399.0| Vadodara|                      60|                 14|            false|      1|Repeat_Sleeping|      5| Anthony Williams|            2|      4|   6798|       10|   [High_Cart_Value]|2015-12-25T18:37:44|                951.72|[3399.0,60.0,14.0...|\n",
      "|2384.3333333333335|   Mumbai|                      67|                 17|            false|      2| Repeat_Churned|      5|     Philip Perez|            3|      4|   7153|       11|                  []|2015-11-06T08:09:34|               1216.01|[2384.33333333333...|\n",
      "|            2978.5|    Delhi|                       6|                 12|            false|      1|  Repeat_Active|      5|      Shawn Avery|            2|      9|   5957|       15|               [NCR]|2015-07-01T01:03:19|                714.84|[2978.5,6.0,12.0,...|\n",
      "|            1328.0|Ahmedabad|                       3|                 22|            false|      2|  Repeat_Active|      4|   Lauren Aguilar|            3|      9|   3984|       15|                  []|2015-07-16T12:23:54|                876.48|[1328.0,3.0,22.0,...|\n",
      "|            3800.5|    Delhi|                      58|                 11|            false|      1|Repeat_Sleeping|      5|       Susan Bray|            2|      5|   7601|       11|[NCR, High_Cart_V...|2016-06-04T19:40:35|                836.11|[3800.5,58.0,11.0...|\n",
      "+------------------+---------+------------------------+-------------------+-----------------+-------+---------------+-------+-----------------+-------------+-------+-------+---------+--------------------+-------------------+----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = output.select(\"features\",'revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           revenue|\n",
      "+-------+------------------+\n",
      "|  count|              4409|\n",
      "|   mean| 8800.925153095941|\n",
      "| stddev|10668.943000398764|\n",
      "|    min|                 0|\n",
      "|    max|             39966|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|          revenue|\n",
      "+-------+-----------------+\n",
      "|  count|             1836|\n",
      "|   mean|9179.119281045752|\n",
      "| stddev|11061.47557354978|\n",
      "|    min|                0|\n",
      "|    max|            39999|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Linear Regression Model object\n",
    "lr = LinearRegression(labelCol='revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the model to the data and call this model lrModel\n",
    "lrModel = lr.fit(train_data,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [1.02358154488,-6.651027152,-270.122598795,801.724802795,294.699621992,107.012946481,-323.75678605,198.184078072,3.06687464563] Intercept: 3704.28065878222\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: {} Intercept: {}\".format(lrModel.coefficients,lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results = lrModel.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|  2308.033572775504|\n",
      "|-116.41878922339674|\n",
      "|  4765.741070534419|\n",
      "| 2881.5339061246063|\n",
      "|-353.28625225793076|\n",
      "|  608.2824620944834|\n",
      "|    4567.8038717949|\n",
      "|   3230.49293212618|\n",
      "|-1084.8176214345362|\n",
      "|-1348.2891930770788|\n",
      "|  4074.115864269826|\n",
      "| 2203.2107541640194|\n",
      "| 4094.0689457258336|\n",
      "|  1570.647984357172|\n",
      "|-1367.4454666228107|\n",
      "|  536.7147792430073|\n",
      "| 3.1206088059202557|\n",
      "|  3284.497957252473|\n",
      "| -75.89490910783161|\n",
      "| 2361.8595071950745|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interesting results....\n",
    "test_results.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_data = test_data.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|            features|         prediction|\n",
      "+--------------------+-------------------+\n",
      "|(9,[1,2,6,7],[3.0...| -2308.033572775504|\n",
      "|(9,[1,2,6,7],[4.0...| 116.41878922339674|\n",
      "|(9,[1,2,6,7],[7.0...| -4765.741070534419|\n",
      "|(9,[1,2,6,7],[8.0...|-2881.5339061246063|\n",
      "|(9,[1,2,6,7],[9.0...| 353.28625225793076|\n",
      "|(9,[1,2,6,7],[10....| -608.2824620944834|\n",
      "|(9,[1,2,6,7],[15....|   -4567.8038717949|\n",
      "|(9,[1,2,6,7],[17....|  -3230.49293212618|\n",
      "|(9,[1,2,6,7],[18....| 1084.8176214345362|\n",
      "|(9,[1,2,6,7],[19....| 1348.2891930770788|\n",
      "|(9,[1,2,6,7],[22....| -4074.115864269826|\n",
      "|(9,[1,2,6,7],[25....|-2203.2107541640194|\n",
      "|(9,[1,2,6,7],[25....|-4094.0689457258336|\n",
      "|(9,[1,2,6,7],[30....| -1570.647984357172|\n",
      "|(9,[1,2,6,7],[35....| 1367.4454666228107|\n",
      "|(9,[1,2,6,7],[37....| -536.7147792430073|\n",
      "|(9,[1,2,6,7],[38....|-3.1206088059202557|\n",
      "|(9,[1,2,6,7],[44....| -3284.497957252473|\n",
      "|(9,[1,2,6,7],[45....|  75.89490910783161|\n",
      "|(9,[1,2,6,7],[46....|-2361.8595071950745|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3442.384629516888\n",
      "MSE: 11850011.93753412\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: {}\".format(test_results.rootMeanSquaredError))\n",
    "print(\"MSE: {}\".format(test_results.meanSquaredError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           revenue|\n",
      "+-------+------------------+\n",
      "|  count|              6245|\n",
      "|   mean| 8912.112409927942|\n",
      "| stddev|10786.315026604458|\n",
      "|    min|                 0|\n",
      "|    max|             39999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select('revenue').describe().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
